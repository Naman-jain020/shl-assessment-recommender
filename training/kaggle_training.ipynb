{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13655790,"sourceType":"datasetVersion","datasetId":8681666}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Keep it light and conflict-free.\n!pip install --quiet beautifulsoup4 requests lxml rank-bm25 lightgbm==4.1.0 scikit-learn==1.4.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:19:23.269287Z","iopub.execute_input":"2025-11-08T10:19:23.269591Z","iopub.status.idle":"2025-11-08T10:19:26.517273Z","shell.execute_reply.started":"2025-11-08T10:19:23.269561Z","shell.execute_reply":"2025-11-08T10:19:26.516373Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import os, re, json, pickle, warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nfrom typing import List, Dict, Tuple\nfrom collections import defaultdict, Counter\n\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom rank_bm25 import BM25Okapi\nimport lightgbm as lgb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:19:35.989964Z","iopub.execute_input":"2025-11-08T10:19:35.990561Z","iopub.status.idle":"2025-11-08T10:19:40.116141Z","shell.execute_reply.started":"2025-11-08T10:19:35.990532Z","shell.execute_reply":"2025-11-08T10:19:40.115500Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Adjust these paths if you uploaded to kaggle datasets; below are common ones:\nTRAIN_PATH = \"/kaggle/input/shldatasetrev/Training Data.csv\"     # rename to your dataset filename\nTEST_PATH  = \"/kaggle/input/shldatasetrev/Testing_data.csv\"\n\n# Fallback if names differ:\nif not os.path.exists(TRAIN_PATH):\n    TRAIN_PATH = \"/kaggle/input/training-data/Training Data.csv\"\nif not os.path.exists(TEST_PATH):\n    TEST_PATH = \"/kaggle/input/testing-data/Testing_data.csv\"\n\ntrain_df = pd.read_csv(TRAIN_PATH)\ntest_df  = pd.read_csv(TEST_PATH)\n\n# Clean “Unnamed” columns from Excel-style exports\ntrain_df = train_df.loc[:, ~train_df.columns.str.contains('^Unnamed')]\ntest_df  = test_df.loc[:,  ~test_df.columns.str.contains('^Unnamed')]\n\nassert {\"Query\",\"Assessment_url\"}.issubset(set(train_df.columns)), \"Training CSV must have Query and Assessment_url columns\"\nassert {\"Query\"}.issubset(set(test_df.columns)), \"Testing CSV must have Query column\"\n\nprint(train_df.shape, train_df.head(3))\nprint(test_df.shape, test_df.head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:20:53.269264Z","iopub.execute_input":"2025-11-08T10:20:53.270520Z","iopub.status.idle":"2025-11-08T10:20:53.342624Z","shell.execute_reply.started":"2025-11-08T10:20:53.270477Z","shell.execute_reply":"2025-11-08T10:20:53.341896Z"}},"outputs":[{"name":"stdout","text":"(65, 2)                                                Query  \\\n0  I am hiring for Java developers who can also c...   \n1  I am hiring for Java developers who can also c...   \n2  I am hiring for Java developers who can also c...   \n\n                                      Assessment_url  \n0  https://www.shl.com/solutions/products/product...  \n1  https://www.shl.com/solutions/products/product...  \n2  https://www.shl.com/solutions/products/product...  \n(9, 1)                                                Query\n0  Looking to hire mid-level professionals who ar...\n1  Job Description\\n\\n Join a community that is s...\n2  I am hiring for an analyst and wants applicati...\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"SESSION = requests.Session()\nSESSION.headers.update({\"User-Agent\":\"Mozilla/5.0\"})\n\ndef fetch_html(url: str, timeout: int = 10) -> str:\n    try:\n        r = SESSION.get(url, timeout=timeout)\n        r.raise_for_status()\n        return r.text\n    except Exception as e:\n        print(f\"[WARN] fetch fail {url}: {e}\")\n        return \"\"\n\ndef parse_assessment(url: str) -> Dict:\n    html = fetch_html(url) if url.startswith(\"http\") else \"\"\n    soup = BeautifulSoup(html, \"lxml\") if html else None\n\n    # Name from URL as fallback\n    name = url.strip(\"/\").split(\"/\")[-1].replace(\"-\", \" \").title()\n    description = \"\"\n    duration = \"\"\n    test_type = \"\"\n\n    if soup:\n        # heuristic text extraction\n        blocks = []\n        for tag in soup.find_all([\"h1\",\"h2\",\"p\",\"li\",\"div\"]):\n            txt = tag.get_text(\" \", strip=True)\n            if txt and len(txt) > 40:\n                blocks.append(txt)\n        description = \" \".join(blocks)[:1200]\n\n        # duration heuristic\n        m = re.search(r\"(\\d+)\\s*(?:min|minutes|minute|hr|hour|hours)\", description, flags=re.I)\n        duration = m.group(0) if m else \"\"\n\n    # test-type heuristic from URL/text\n    lower_blob = (name + \" \" + description + \" \" + url).lower()\n    if any(k in lower_blob for k in [\"opq\",\"personality\",\"behavior\",\"behaviour\"]):\n        test_type = \"P\"\n    elif any(k in lower_blob for k in [\"cognitive\",\"numerical\",\"verbal\",\"inductive\",\"deductive\",\"reasoning\",\"aptitude\"]):\n        test_type = \"C\"\n    else:\n        test_type = \"K\"\n\n    # keyword bag\n    skill_lex = [\n        \"java\",\"python\",\"sql\",\"javascript\",\"js\",\"html\",\"css\",\"selenium\",\"excel\",\"tableau\",\n        \"communication\",\"leadership\",\"collaboration\",\"stakeholder\",\"analytical\",\"problem solving\",\n        \"sales\",\"marketing\",\"customer\",\"support\",\"data\",\"programming\",\"coding\",\"qa\",\"quality\"\n    ]\n    keywords = sorted({w for w in skill_lex if w in lower_blob})\n\n    return {\n        \"url\": url,\n        \"name\": name,\n        \"description\": description,\n        \"duration\": duration,\n        \"test_type\": test_type,\n        \"keywords\": keywords\n    }\n\n# Build catalog strictly from training URLs (works when internet off)\ncatalog_urls = sorted(train_df[\"Assessment_url\"].dropna().unique().tolist())\ncatalog = []\nfor u in catalog_urls:\n    catalog.append(parse_assessment(u))\n\ncatalog_df = pd.DataFrame(catalog)\nprint(\"Catalog size:\", len(catalog_df))\ncatalog_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:21:11.349309Z","iopub.execute_input":"2025-11-08T10:21:11.349588Z","iopub.status.idle":"2025-11-08T10:23:54.026488Z","shell.execute_reply.started":"2025-11-08T10:21:11.349567Z","shell.execute_reply":"2025-11-08T10:23:54.025845Z"}},"outputs":[{"name":"stdout","text":"Catalog size: 54\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                 url  \\\n0  https://www.shl.com/products/product-catalog/v...   \n1  https://www.shl.com/products/product-catalog/v...   \n2  https://www.shl.com/products/product-catalog/v...   \n\n                               name  \\\n0   Business Communication Adaptive   \n1         English Comprehension New   \n2  Enterprise Leadership Report 2 0   \n\n                                         description duration test_type  \\\n0  Outdated browser detected We recommend upgradi...                  K   \n1  Outdated browser detected We recommend upgradi...                  K   \n2  Outdated browser detected We recommend upgradi...                  K   \n\n                   keywords  \n0  [communication, support]  \n1                 [support]  \n2     [leadership, support]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>name</th>\n      <th>description</th>\n      <th>duration</th>\n      <th>test_type</th>\n      <th>keywords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.shl.com/products/product-catalog/v...</td>\n      <td>Business Communication Adaptive</td>\n      <td>Outdated browser detected We recommend upgradi...</td>\n      <td></td>\n      <td>K</td>\n      <td>[communication, support]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.shl.com/products/product-catalog/v...</td>\n      <td>English Comprehension New</td>\n      <td>Outdated browser detected We recommend upgradi...</td>\n      <td></td>\n      <td>K</td>\n      <td>[support]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.shl.com/products/product-catalog/v...</td>\n      <td>Enterprise Leadership Report 2 0</td>\n      <td>Outdated browser detected We recommend upgradi...</td>\n      <td></td>\n      <td>K</td>\n      <td>[leadership, support]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Unified text for each assessment\ndef assessment_text(row) -> str:\n    parts = [\n        (row.get(\"name\") or \"\"),\n        (row.get(\"description\") or \"\"),\n        \" \".join(row.get(\"keywords\") or []),\n        row.get(\"test_type\") or \"\"\n    ]\n    return \" \".join(parts)\n\ncatalog_df[\"text\"] = catalog_df.apply(assessment_text, axis=1)\n\n# Tokenization for BM25\ndef tokenize(s: str) -> List[str]:\n    s = s.lower()\n    s = re.sub(r\"[^a-z0-9+.# ]+\", \" \", s)\n    return s.split()\n\n# Build BM25 corpus\nbm25_corpus = [tokenize(t) for t in catalog_df[\"text\"].tolist()]\nbm25 = BM25Okapi(bm25_corpus)\n\n# TF-IDF\ntfidf = TfidfVectorizer(ngram_range=(1,2), min_df=1, max_df=0.9)\ntfidf_mat = tfidf.fit_transform(catalog_df[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:24:33.999395Z","iopub.execute_input":"2025-11-08T10:24:34.000125Z","iopub.status.idle":"2025-11-08T10:24:34.050942Z","shell.execute_reply.started":"2025-11-08T10:24:34.000098Z","shell.execute_reply":"2025-11-08T10:24:34.050299Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Lexicons for skills and soft-skills to detect \"diverse\" needs\nTECH = set([\"java\",\"python\",\"sql\",\"javascript\",\"js\",\"html\",\"css\",\"selenium\",\"excel\",\"tableau\",\"react\",\"node\",\"mongodb\",\"mysql\",\"postgresql\"])\nSOFT = set([\"communication\",\"leadership\",\"teamwork\",\"collaboration\",\"stakeholder\",\"problem solving\",\"analytical\",\"creativity\",\"adaptability\",\"management\",\"interpersonal\"])\n\ndef extract_requirements(query: str) -> Dict:\n    q = query.lower()\n    tech = sorted({w for w in TECH if w in q})\n    soft = sorted({w for w in SOFT if w in q})\n    needs_diversity = bool(tech and soft)\n    # duration\n    dur = None\n    m = re.search(r\"(\\d+)\\s*(min|minute|hour|hr)\", q)\n    if m:\n        dur = int(m.group(1)) * (60 if \"hour\" in m.group(2) or \"hr\" in m.group(2) else 1)\n    return {\"tech\":tech,\"soft\":soft,\"needs_diversity\":needs_diversity,\"duration\":dur}\n\ndef jaccard(a: List[str], b: List[str]) -> float:\n    A, B = set(a), set(b)\n    if not A and not B: return 0.0\n    return len(A & B) / len(A | B)\n\ndef features_for(query: str, topN: int = 80) -> Tuple[np.ndarray, List[int]]:\n    \"\"\"Generate candidate set (BM25) then compute dense features for reranking.\"\"\"\n    q_tokens = tokenize(query)\n    bm25_scores = bm25.get_scores(q_tokens)\n    # Top candidates by BM25\n    cand_idx = np.argsort(-bm25_scores)[:topN]\n\n    # TF-IDF cosine vs catalog rows\n    q_vec = tfidf.transform([query])\n    cosines = cosine_similarity(q_vec, tfidf_mat[cand_idx]).ravel()\n\n    req = extract_requirements(query)\n    feats = []\n    for rank_pos, i in enumerate(cand_idx):\n        row = catalog_df.iloc[i]\n        text_tok = bm25_corpus[i]\n\n        f = []\n        # 1) BM25 score\n        f.append(bm25_scores[i])\n        # 2) TF-IDF cosine\n        f.append(cosines[rank_pos])\n        # 3) token overlap\n        f.append(len(set(q_tokens) & set(text_tok)))\n        f.append(jaccard(q_tokens, text_tok))\n        # 4) keyword overlaps\n        f.append(sum(1 for w in req[\"tech\"] if w in (row[\"text\"].lower())))\n        f.append(sum(1 for w in req[\"soft\"] if w in (row[\"text\"].lower())))\n        # 5) test type match preferences (if both -> neutral; if only tech -> bias K; only soft -> bias P)\n        tt = row.get(\"test_type\",\"\")\n        prefer_k = bool(req[\"tech\"] and not req[\"soft\"])\n        prefer_p = bool(req[\"soft\"] and not req[\"tech\"])\n        f.append(1.0 if (prefer_k and tt==\"K\") else 0.0)\n        f.append(1.0 if (prefer_p and tt==\"P\") else 0.0)\n        # 6) url signal (token hits inside url)\n        url = (row[\"url\"] or \"\").lower()\n        f.append(sum(1 for w in req[\"tech\"] if w in url))\n        f.append(sum(1 for w in req[\"soft\"] if w in url))\n\n        feats.append(f)\n\n    return np.array(feats, dtype=np.float32), cand_idx.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:24:49.656374Z","iopub.execute_input":"2025-11-08T10:24:49.656994Z","iopub.status.idle":"2025-11-08T10:24:49.668017Z","shell.execute_reply.started":"2025-11-08T10:24:49.656966Z","shell.execute_reply":"2025-11-08T10:24:49.667184Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# For each unique training query, mark positives from labels and sample negatives from catalog.\ntrain_queries = train_df[\"Query\"].unique().tolist()\nq_records = []\n\nfor q in train_queries:\n    pos_urls = set(train_df.loc[train_df[\"Query\"]==q, \"Assessment_url\"].dropna().tolist())\n\n    X, cand_idx = features_for(q, topN=min(120, len(catalog_df)))\n    urls = catalog_df.iloc[cand_idx][\"url\"].tolist()\n\n    y = np.array([1 if u in pos_urls else 0 for u in urls], dtype=np.int32)\n\n    # Keep all positives + a set of hardest negatives (top BM25 but not in pos)\n    keep_mask = (y==1)\n    neg_candidates = np.where((y==0))[0].tolist()\n    # take top pile of negatives (already sorted by BM25 order due to cand list)\n    neg_keep = neg_candidates[:max(10, min(50, len(neg_candidates)))]\n    keep_mask[neg_keep] = True\n\n    X_keep = X[keep_mask]\n    y_keep = y[keep_mask]\n    urls_keep = np.array(urls)[keep_mask].tolist()\n\n    q_records.append({\"query\": q, \"X\": X_keep, \"y\": y_keep, \"urls\": urls_keep})\n\n# Concatenate into LGBMRanker input\nX_list, y_list, group = [], [], []\nfor rec in q_records:\n    X_list.append(rec[\"X\"])\n    y_list.append(rec[\"y\"])\n    group.append(len(rec[\"y\"]))\nX_train = np.vstack(X_list)\ny_train = np.concatenate(y_list)\n\nprint(\"Train matrix:\", X_train.shape, \" Positives:\", int(y_train.sum()), \" Groups:\", len(group))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:25:02.710103Z","iopub.execute_input":"2025-11-08T10:25:02.710611Z","iopub.status.idle":"2025-11-08T10:25:02.821121Z","shell.execute_reply.started":"2025-11-08T10:25:02.710590Z","shell.execute_reply":"2025-11-08T10:25:02.820550Z"}},"outputs":[{"name":"stdout","text":"Train matrix: (540, 10)  Positives: 65  Groups: 10\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def recall_at_k_for_query(q: str, booster, k=10) -> float:\n    feats, cidx = features_for(q, topN=min(120, len(catalog_df)))\n    scores = booster.predict(feats)\n    order = np.argsort(-scores)\n    top_idx = [cidx[i] for i in order[:k]]\n    rec_urls = set(catalog_df.iloc[top_idx][\"url\"].tolist())\n\n    gold = set(train_df.loc[train_df[\"Query\"]==q, \"Assessment_url\"].tolist())\n    if not gold: return 0.0\n    return len(rec_urls & gold) / len(gold)\n\ndef mean_recall_at_k(booster, k=10) -> float:\n    vals = [recall_at_k_for_query(q, booster, k=k) for q in train_queries]\n    return float(np.mean(vals)) if vals else 0.0\n\nparams = dict(\n    objective=\"lambdarank\",\n    metric=\"ndcg\",\n    boosting_type=\"gbdt\",\n    num_leaves=63,\n    learning_rate=0.06,\n    min_data_in_leaf=10,\n    feature_fraction=0.9,\n    bagging_fraction=0.8,\n    bagging_freq=1,\n    max_depth=-1,\n    verbose=-1\n)\n\ndtrain = lgb.Dataset(X_train, label=y_train, group=group, free_raw_data=False)\n\nRECALL_K = 10\nEVAL_EVERY = 10\nNUM_BOOST_ROUNDS = 200\n\nrecall_history = []\n\ndef recall_callback(env):\n    # Called at the end of each iteration\n    iter_ = env.iteration + 1\n    if iter_ % EVAL_EVERY == 0 or iter_ == 1:\n        booster = env.model\n        r = mean_recall_at_k(booster, k=RECALL_K)\n        recall_history.append((iter_, r))\n        print(f\"[Round {iter_:3d}] Mean Recall@{RECALL_K}: {r:.4f}\")\n\nranker = lgb.train(\n    params,\n    dtrain,\n    num_boost_round=NUM_BOOST_ROUNDS,\n    valid_sets=[dtrain],\n    valid_names=[\"train\"],\n    callbacks=[lgb.log_evaluation(period=EVAL_EVERY), recall_callback]\n)\n\nprint(\"\\nFinal Mean Recall@10:\", f\"{mean_recall_at_k(ranker, k=10):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:25:15.995797Z","iopub.execute_input":"2025-11-08T10:25:15.996524Z","iopub.status.idle":"2025-11-08T10:25:18.449228Z","shell.execute_reply.started":"2025-11-08T10:25:15.996490Z","shell.execute_reply":"2025-11-08T10:25:18.448463Z"}},"outputs":[{"name":"stdout","text":"[Round   1] Mean Recall@10: 0.5811\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round  10] Mean Recall@10: 0.6856\n[10]\ttrain's ndcg@1: 0.9\ttrain's ndcg@2: 0.861315\ttrain's ndcg@3: 0.8\ttrain's ndcg@4: 0.749562\ttrain's ndcg@5: 0.716818\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round  20] Mean Recall@10: 0.7356\n[20]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 0.922629\ttrain's ndcg@3: 0.846928\ttrain's ndcg@4: 0.805412\ttrain's ndcg@5: 0.75222\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round  30] Mean Recall@10: 0.7722\n[30]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 0.961315\ttrain's ndcg@3: 0.876536\ttrain's ndcg@4: 0.81323\ttrain's ndcg@5: 0.759012\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round  40] Mean Recall@10: 0.7922\n[40]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 0.961315\ttrain's ndcg@3: 0.876536\ttrain's ndcg@4: 0.81323\ttrain's ndcg@5: 0.759012\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round  50] Mean Recall@10: 0.7989\n[50]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.88268\ttrain's ndcg@4: 0.835154\ttrain's ndcg@5: 0.77806\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round  60] Mean Recall@10: 0.7733\n[60]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.88268\ttrain's ndcg@4: 0.851967\ttrain's ndcg@5: 0.779546\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round  70] Mean Recall@10: 0.7900\n[70]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.88268\ttrain's ndcg@4: 0.851967\ttrain's ndcg@5: 0.779546\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round  80] Mean Recall@10: 0.8100\n[80]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.83786\ttrain's ndcg@5: 0.780411\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round  90] Mean Recall@10: 0.8100\n[90]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.83786\ttrain's ndcg@5: 0.780411\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 100] Mean Recall@10: 0.8211\n[100]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.854673\ttrain's ndcg@5: 0.781897\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 110] Mean Recall@10: 0.8422\n[110]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.871486\ttrain's ndcg@5: 0.796504\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 120] Mean Recall@10: 0.8422\n[120]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.83786\ttrain's ndcg@5: 0.780411\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 130] Mean Recall@10: 0.8422\n[130]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.83786\ttrain's ndcg@5: 0.780411\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 140] Mean Recall@10: 0.8422\n[140]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 0.961315\ttrain's ndcg@3: 0.9\ttrain's ndcg@4: 0.849562\ttrain's ndcg@5: 0.777456\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 150] Mean Recall@10: 0.8422\n[150]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.854673\ttrain's ndcg@5: 0.781897\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 160] Mean Recall@10: 0.8422\n[160]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.83786\ttrain's ndcg@5: 0.780411\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 170] Mean Recall@10: 0.8422\n[170]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.83786\ttrain's ndcg@5: 0.780411\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 180] Mean Recall@10: 0.8422\n[180]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 0.961315\ttrain's ndcg@3: 0.9\ttrain's ndcg@4: 0.849562\ttrain's ndcg@5: 0.777456\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 190] Mean Recall@10: 0.8422\n[190]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 0.961315\ttrain's ndcg@3: 0.9\ttrain's ndcg@4: 0.832749\ttrain's ndcg@5: 0.789091\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[Round 200] Mean Recall@10: 0.8422\n[200]\ttrain's ndcg@1: 1\ttrain's ndcg@2: 1\ttrain's ndcg@3: 0.906144\ttrain's ndcg@4: 0.821047\ttrain's ndcg@5: 0.792045\n\nFinal Mean Recall@10: 0.8422\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def recommend(query: str, k: int = 10, balance=True) -> List[str]:\n    feats, cidx = features_for(query, topN=min(200, len(catalog_df)))\n    scores = ranker.predict(feats)\n    order = np.argsort(-scores)\n\n    if not balance:\n        top_idx = [cidx[i] for i in order[:k]]\n        return catalog_df.iloc[top_idx][\"url\"].tolist()\n\n    req = extract_requirements(query)\n    # split by test_type\n    ranked = [{\"idx\": cidx[i], \"score\": float(scores[i]),\n               \"tt\": catalog_df.iloc[cidx[i]][\"test_type\"]} for i in order]\n\n    if req[\"needs_diversity\"]:\n        # 50% K, 30% P, 20% C\n        tk = max(1, int(0.5 * k))\n        tp = max(1, int(0.3 * k))\n        tc = max(1, k - tk - tp)\n        buckets = {\"K\":[], \"P\":[], \"C\":[]}\n        for r in ranked:\n            buckets.get(r[\"tt\"], []).append(r)\n\n        take = []\n        take += buckets[\"K\"][:tk]\n        take += buckets[\"P\"][:tp]\n        take += buckets[\"C\"][:tc]\n\n        if len(take) < k:\n            # fill remainder by global score\n            used = set(x[\"idx\"] for x in take)\n            for r in ranked:\n                if r[\"idx\"] not in used:\n                    take.append(r)\n                if len(take) == k: break\n\n        take = sorted(take, key=lambda x: -x[\"score\"])[:k]\n        top_idx = [x[\"idx\"] for x in take]\n    else:\n        top_idx = [cidx[i] for i in order[:k]]\n\n    return catalog_df.iloc[top_idx][\"url\"].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T11:06:40.740080Z","iopub.execute_input":"2025-11-08T11:06:40.740632Z","iopub.status.idle":"2025-11-08T11:06:40.749206Z","shell.execute_reply.started":"2025-11-08T11:06:40.740600Z","shell.execute_reply":"2025-11-08T11:06:40.748498Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def eval_on_training(k=10):\n    recalls = []\n    for q in train_queries:\n        gold = set(train_df.loc[train_df[\"Query\"]==q, \"Assessment_url\"].tolist())\n        pred = set(recommend(q, k=k, balance=True))\n        rec = 0.0 if not gold else len(gold & pred) / len(gold)\n        recalls.append(rec)\n        print(f\"Recall@{k}: {rec:.3f} | {q[:80]}...\")\n    print(f\"\\nMean Recall@{k}: {np.mean(recalls):.4f}\")\n\neval_on_training(k=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T11:06:45.539300Z","iopub.execute_input":"2025-11-08T11:06:45.540099Z","iopub.status.idle":"2025-11-08T11:06:45.673281Z","shell.execute_reply.started":"2025-11-08T11:06:45.540067Z","shell.execute_reply":"2025-11-08T11:06:45.672619Z"}},"outputs":[{"name":"stdout","text":"Recall@10: 0.800 | I am hiring for Java developers who can also collaborate effectively with my bus...\nRecall@10: 0.889 | I want to hire new graduates for a sales role in my company, the budget is for a...\nRecall@10: 0.667 | I am looking for a COO for my company in China and I want to see if they are cul...\nRecall@10: 0.800 | KEY RESPONSIBITILES:\n\nManage the sound-scape of the station through appropriate ...\nRecall@10: 0.600 | Content Writer required, expert in English and SEO....\nRecall@10: 0.556 | Find me 1 hour long assesment for the below job at SHL\nJob Description\n\n Join a ...\nRecall@10: 0.667 | ICICI Bank Assistant Admin, Experience required 0-2 years, test should be 30-40 ...\nRecall@10: 1.000 | We're looking for a Marketing Manager who can drive Recro’s brand positioning, c...\nRecall@10: 1.000 | Based on the JD below recommend me assessment for the Consultant position in my ...\nRecall@10: 0.800 | I want to hire a Senior Data Analyst with 5 years of experience and expertise in...\n\nMean Recall@10: 0.7778\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"pred_rows = []\nfor _, row in test_df.iterrows():\n    q = row[\"Query\"]\n    urls = recommend(q, k=10, balance=True)\n    for u in urls:\n        pred_rows.append({\"Query\": q, \"Assessment_url\": u})\n\npred_df = pd.DataFrame(pred_rows)\npred_df.to_csv(\"predictions.csv\", index=False)\nprint(\"Saved predictions.csv with\", len(pred_df), \"rows\")\n\npred_df.head(12)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T11:06:49.773892Z","iopub.execute_input":"2025-11-08T11:06:49.774406Z","iopub.status.idle":"2025-11-08T11:06:49.919375Z","shell.execute_reply.started":"2025-11-08T11:06:49.774384Z","shell.execute_reply":"2025-11-08T11:06:49.918756Z"}},"outputs":[{"name":"stdout","text":"Saved predictions.csv with 90 rows\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                                Query  \\\n0   Looking to hire mid-level professionals who ar...   \n1   Looking to hire mid-level professionals who ar...   \n2   Looking to hire mid-level professionals who ar...   \n3   Looking to hire mid-level professionals who ar...   \n4   Looking to hire mid-level professionals who ar...   \n5   Looking to hire mid-level professionals who ar...   \n6   Looking to hire mid-level professionals who ar...   \n7   Looking to hire mid-level professionals who ar...   \n8   Looking to hire mid-level professionals who ar...   \n9   Looking to hire mid-level professionals who ar...   \n10  Job Description\\n\\n Join a community that is s...   \n11  Job Description\\n\\n Join a community that is s...   \n\n                                       Assessment_url  \n0   https://www.shl.com/solutions/products/product...  \n1   https://www.shl.com/solutions/products/product...  \n2   https://www.shl.com/solutions/products/product...  \n3   https://www.shl.com/solutions/products/product...  \n4   https://www.shl.com/solutions/products/product...  \n5   https://www.shl.com/solutions/products/product...  \n6   https://www.shl.com/solutions/products/product...  \n7   https://www.shl.com/solutions/products/product...  \n8   https://www.shl.com/solutions/products/product...  \n9   https://www.shl.com/solutions/products/product...  \n10  https://www.shl.com/solutions/products/product...  \n11  https://www.shl.com/solutions/products/product...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Query</th>\n      <th>Assessment_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Looking to hire mid-level professionals who ar...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Job Description\\n\\n Join a community that is s...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Job Description\\n\\n Join a community that is s...</td>\n      <td>https://www.shl.com/solutions/products/product...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"artifacts = {\n    \"catalog_df\": catalog_df.to_dict(orient=\"list\"),\n    \"tfidf_vocab\": tfidf.vocabulary_,\n    \"tfidf_idf\": tfidf.idf_.tolist(),\n    \"params\": params,\n}\n\n# LightGBM model\nranker.save_model(\"lgbm_ltr.txt\")\n\n# BM25 components\nwith open(\"bm25_tokens.pkl\", \"wb\") as f:\n    pickle.dump(bm25_corpus, f)\n\nwith open(\"artifacts.json\", \"w\") as f:\n    json.dump(artifacts, f)\n\nprint(\"Saved: lgbm_ltr.txt, bm25_tokens.pkl, artifacts.json, predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T11:06:52.618738Z","iopub.execute_input":"2025-11-08T11:06:52.619293Z","iopub.status.idle":"2025-11-08T11:06:52.638996Z","shell.execute_reply.started":"2025-11-08T11:06:52.619272Z","shell.execute_reply":"2025-11-08T11:06:52.638384Z"}},"outputs":[{"name":"stdout","text":"Saved: lgbm_ltr.txt, bm25_tokens.pkl, artifacts.json, predictions.csv\n","output_type":"stream"}],"execution_count":27}]}